{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd30894-f064-4052-a902-34db7cfde6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0af889a-4a36-4600-8f34-9a85b59d4297",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install 'numpy<2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bebfcc77-9d74-4b50-9896-2375e01c5eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os import path\n",
    "import spacy\n",
    "import json\n",
    "from json import loads\n",
    "from spacy.tokens import Token\n",
    "from spacy.tokens import DocBin\n",
    "import sys\n",
    "import re\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d7c7a97-70a4-4908-8e87-d14daeabc66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 -m spacy download ro_core_news_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61bd9be-5fe9-4276-b720-bb4015dec957",
   "metadata": {},
   "outputs": [],
   "source": [
    "ron_nlp = spacy.load('ro_core_news_lg')\n",
    "ron_nlp._path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b477719-ca4a-4418-a913-13cba028a03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "syllabic_rwp = ['mă', 'te', 'lu', 'se', 'mi', 'ți', 'i', 'și', 'ne', 'vă', 'le', 'ni', 'vi', 'li']\n",
    "# the o-RWP behaves as an auxiliary verb with vocalic onset\n",
    "vocalic_rwp = ['o']\n",
    "syllabic_rwv = ['su', 'i']\n",
    "syllabic_neg = ['nu']\n",
    "auxiliary_verb = ['am', 'ai', 'a', 'ați', 'au', 'aș', 'ar', 'oi', 'om', 'oți', 'or', 'voi', 'vei', 'va', 'vom', 'veți', 'vor']\n",
    "\n",
    "ron_vowels = \"aeiouăîâ\"\n",
    "\n",
    "EMPTY_TOKEN = ron_nlp('#')[0]\n",
    "EMPTY_TOKEN.pos_ = \"PUNCT\" \n",
    "HYPHEN_TOKEN =  ron_nlp('-')[0]\n",
    "\n",
    "# Define getter functions\n",
    "def get_is_rwp(token):\n",
    "    return token.lower_ in syllabic_rwp and token.pos_ != \"CCONJ\" # to check with 'și'\n",
    "\n",
    "def get_is_vocalic_rwp(token):\n",
    "    return token.lower_ in vocalic_rwp and token.pos_ != \"DET\" # to check with 'o casă'\n",
    "\n",
    "def get_is_rwv(token):\n",
    "    return token.lower_ in syllabic_rwv\n",
    "\n",
    "def get_is_neg(token):\n",
    "    return token.lower_ in syllabic_neg\n",
    "\n",
    "def get_is_auxiliary_verb(token):\n",
    "    return token.lower_ in auxiliary_verb and token.pos_ != \"VERB\" and token.pos_ != \"PART\" and token.pos_ != \"DET\"\n",
    "\n",
    "def get_is_obligatory_host(token):\n",
    "    return (get_is_auxiliary_verb(token) and get_vowel_initial_char(token)) or get_is_vocalic_rwp(token) \n",
    "\n",
    "# in the context of Romanian weak pronouns, a linear order part is an item that can occurr in both pre- and post-verbal position\n",
    "# such as the sequence \"le\" in \"Le faci.\"  vs \"Fă-le!\" or the sequence \"mi le\" in \"Mi le dai. vs \"Dă-mi-le!\"\n",
    "# ==> pointer to article\n",
    "\n",
    "def get_is_linear_order_part(token):\n",
    "    return get_is_rwp(token) or get_is_vocalic_rwp(token) or get_is_auxiliary_verb(token) or get_is_rwv(token)\n",
    "\n",
    "def get_vowel_initial_char(token):\n",
    "    return token.lower_[0] in ron_vowels \n",
    "\n",
    "def get_vowel_final_char(token):\n",
    "    return token.lower_[len(token.lower_)-1] in ron_vowels \n",
    "\n",
    "def get_vowel_initial(token):\n",
    "    return token.lower_[0] in ron_vowels and not token.lower_.startswith('iu')\n",
    "\n",
    "def get_vowel_final(token):\n",
    "    return token.lower_[len(token.lower_)-1] in ron_vowels and not \\\n",
    "    (token.lower_.endswith('ui') or token.lower_.endswith('oi') or token.lower_.endswith('eu'))\n",
    "\n",
    "def get_is_first_syllable_stressed(token):\n",
    "    firstSyllableStressed = False\n",
    "    if token.lower_ == 'umbli' or (token.lower_ == 'am' and token.pos_ == 'VERB') or \\\n",
    "        (token.lower_ == 'este' and token.pos_ == 'AUX')  or \\\n",
    "        (token.lower_ == 'aflu' and token.pos_ == 'VERB') or \\\n",
    "        (token.lower_ == 'arde' and token.pos_ == 'VERB') or \\\n",
    "        (token.lower_ == 'altuia'):\n",
    "        firstSyllableStressed = True\n",
    "    return firstSyllableStressed \n",
    "\n",
    "def get_is_last_syllable_stressed(token):\n",
    "    return False \n",
    "\n",
    "# Set extension on the Token with getter\n",
    "Token.set_extension(\"is_rwp\", getter=get_is_rwp, force=True)\n",
    "Token.set_extension(\"is_vocalic_rwp\", getter=get_is_vocalic_rwp, force=True)\n",
    "Token.set_extension(\"is_rwv\", getter=get_is_rwv, force=True)\n",
    "Token.set_extension(\"is_neg\", getter=get_is_neg, force=True)\n",
    "Token.set_extension(\"is_auxiliary_verb\", getter=get_is_auxiliary_verb, force=True)\n",
    "Token.set_extension(\"is_obligatory_host\", getter=get_is_obligatory_host, force=True)\n",
    "Token.set_extension(\"is_linear_order_part\", getter=get_is_linear_order_part, force=True)\n",
    "Token.set_extension(\"vowel_initial_char\", getter=get_vowel_initial_char, force=True)\n",
    "Token.set_extension(\"vowel_final_char\", getter=get_vowel_final_char, force=True)\n",
    "Token.set_extension(\"vowel_initial\", getter=get_vowel_initial, force=True)\n",
    "Token.set_extension(\"vowel_final\", getter=get_vowel_final, force=True)\n",
    "Token.set_extension(\"is_first_syllable_stressed\", getter=get_is_first_syllable_stressed, force=True)\n",
    "Token.set_extension(\"is_last_syllable_stressed\", getter=get_is_last_syllable_stressed, force=True)\n",
    "\n",
    "def get_asyllabic_form(underlying_representation, sandhi):\n",
    "    asyllabic_form = \"\"\n",
    "    if underlying_representation == \"mă\":\n",
    "        asyllabic_form = \"m\"\n",
    "    elif underlying_representation == \"vă\":\n",
    "        asyllabic_form = \"v\"\n",
    "    elif  underlying_representation == \"nu\":\n",
    "        asyllabic_form = \"n\"\n",
    "    elif  underlying_representation == \"lu\":\n",
    "        asyllabic_form = \"l\"\n",
    "    elif  underlying_representation == \"su\":\n",
    "        asyllabic_form = \"s\"\n",
    "    elif  underlying_representation == \"o\":\n",
    "        asyllabic_form = \"o\"\n",
    "    elif  underlying_representation == \"se\" and sandhi == \"OBLIGATORY\":\n",
    "        asyllabic_form = \"s\"\n",
    "    # disallow the forms \"s-aduce\", allow only \"se-aduce\" to decrease possible ambiguity \n",
    "    # between the RWP \"se\" and the subjunction \"să\" as in \"s-aduc\" vs. \"să aduca\"\n",
    "    elif  underlying_representation == \"se\" and sandhi != \"OBLIGATORY\":\n",
    "        asyllabic_form = \"se\"\n",
    "    elif  underlying_representation == \"te\":\n",
    "        asyllabic_form = \"te\"\n",
    "    elif  underlying_representation == \"ne\":\n",
    "        asyllabic_form = \"ne\"\n",
    "    elif  underlying_representation == \"le\":\n",
    "        asyllabic_form = \"le\"\n",
    "    elif underlying_representation == \"mi\":\n",
    "        asyllabic_form = \"mi\"\n",
    "    elif underlying_representation == \"ți\":\n",
    "        asyllabic_form = \"ți\"\n",
    "    elif underlying_representation == \"i\":\n",
    "        asyllabic_form = \"i\"\n",
    "    elif underlying_representation == \"și\":\n",
    "        asyllabic_form = \"și\"\n",
    "    elif underlying_representation == \"ni\":\n",
    "        asyllabic_form = \"ni\"\n",
    "    elif underlying_representation == \"vi\":\n",
    "        asyllabic_form = \"vi\"\n",
    "    elif underlying_representation == \"li\":\n",
    "        asyllabic_form = \"li\"\n",
    "    return asyllabic_form\n",
    "\n",
    "# coping with ni => ne, vi => vă, and li => le\n",
    "def get_interim_form(underlying_representation):\n",
    "    interim_form = \"\"\n",
    "    if underlying_representation == \"ni\":\n",
    "        interim_form = \"ne\"\n",
    "    elif underlying_representation == \"vi\":\n",
    "        interim_form = \"vă\"\n",
    "    elif underlying_representation == \"li\":\n",
    "        interim_form = \"le\"\n",
    "    else:\n",
    "        interim_form = underlying_representation\n",
    "    return interim_form\n",
    "    \n",
    "# get immediate left token\n",
    "def get_lnbor(token):\n",
    "    l_nbor = EMPTY_TOKEN\n",
    "    if  token.i > 0:\n",
    "        l_nbor = token.nbor(-1)\n",
    "    return l_nbor\n",
    "    \n",
    "# get immediate right token\n",
    "def get_rnbor(token):\n",
    "    r_nbor = EMPTY_TOKEN\n",
    "    if token.i < len(token.doc)-1:\n",
    "        r_nbor = token.nbor(1)\n",
    "    return r_nbor\n",
    "\n",
    "def is_rightmost_in_cluster(token):\n",
    "    r_nbor = get_rnbor(token)\n",
    "    return (token._.is_rwp or token._.is_rwv) and not (r_nbor._.is_rwp or r_nbor._.is_rwv)\n",
    "\n",
    "def is_leftmost_in_cluster(token):\n",
    "    l_nbor = get_lnbor(token)\n",
    "    return (token._.is_rwp or token._.is_rwv) and not (l_nbor._.is_rwp or l_nbor._.is_rwv)\n",
    "\n",
    "def is_singleton_in_cluster(token):\n",
    "    return is_rightmost_in_cluster(token) and is_leftmost_in_cluster(token)\n",
    "\n",
    "def is_preverbal(token):\n",
    "    preverbality = None\n",
    "    theDoc = token.doc\n",
    "    for lt in range(token.i, -1, -1):\n",
    "        if token._.is_linear_order_part and theDoc[lt-1]._.is_linear_order_part:\n",
    "            pass\n",
    "        else:\n",
    "            if (theDoc[lt-1].pos_ != 'VERB' and theDoc[lt-1].pos_ != 'INTJ') or theDoc[lt].pos_ == 'VERB':\n",
    "                preverbality =  True\n",
    "                break\n",
    "            else:\n",
    "                preverbality =  False\n",
    "                break\n",
    "    return preverbality\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68361487-f437-4ed3-a8a4-fee75bb49d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def filterOutput(originalOutput):\n",
    "    filteredOutput = []\n",
    "    unique_list = []\n",
    "    pattern01 = re.compile(r' î..-|.{2,}-.{2}-mb|într-o-|nu-ntr|\\S{2,}-nainte|-avea|de-a se |aduce-napoi|[aeiouăîâ]-î|putea-neca')\n",
    "    \n",
    "    for opt in originalOutput:\n",
    "        match01 = re.search(pattern01, opt)\n",
    "        if not match01:\n",
    "            filteredOutput.append(opt)\n",
    "\n",
    "    for x in filteredOutput:\n",
    "        if x not in unique_list:\n",
    "            unique_list.append(x)\n",
    "    \n",
    "    return unique_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac680d0-c8c1-491c-9069-a056e46825fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def indexOutput(filteredOutput, id, targets):\n",
    "    genOput = {}\n",
    "\n",
    "    for i,v in enumerate(filteredOutput):\n",
    "        oputKey = 'ex'+id+'_o'+str(i+1)\n",
    "        genOput[oputKey] = v\n",
    "    return genOput\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f190f0ac-b916-4a64-934a-35de538f49ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def getEvaluation(filteredOutput, id, targets):\n",
    "    genEval = {}\n",
    "    for i,v in enumerate(filteredOutput):\n",
    "        evalKey = 'ex'+id+'_e'+str(i+1)\n",
    "        if v in targets.values():\n",
    "            genEval[evalKey] = 'ok'\n",
    "        else:\n",
    "            genEval[evalKey] = 'ko'\n",
    "\n",
    "    trgLen = len(targets)\n",
    "    oputLen = len(filteredOutput)\n",
    "    okLen = sum(x == 'ok' for x in genEval.values())\n",
    "    \n",
    "    progressLabel = 'done' if trgLen == okLen and trgLen == oputLen else 'todo'\n",
    "    progress = progressLabel + ' _ ' + str(oputLen)  + '|' + str(okLen) + ' > ' + str(trgLen)\n",
    "        \n",
    "    return [genEval, progress]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e6296e6-9729-4121-93cb-bd9d3f71855b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "logDir = 'logDir_1'\n",
    "genDir = 'genDir_1'\n",
    "\n",
    "if not path.exists(logDir):\n",
    "   os.makedirs(logDir)\n",
    "\n",
    "if not path.exists(genDir):\n",
    "   os.makedirs(genDir)\n",
    "\n",
    "# output version suffix to compare and debug if needed\n",
    "v_suffix = '88'\n",
    "\n",
    "logFile = path.join(logDir, 'logfile_' + v_suffix + '.log')\n",
    "genFile = path.join(genDir, 'genOpt_' + v_suffix + '.json')\n",
    "\n",
    "iputDocs = \"spacyAnnotation/rwp_352_corrected_annotation.spacy\"\n",
    "spacyDocuments = DocBin().from_disk(iputDocs)\n",
    "\n",
    "iputRWP = \"input_rwp_352.json\"\n",
    "with open(iputRWP) as input_json_file:\n",
    "    rwpDB = json.load(input_json_file)\n",
    "\n",
    "blank_nlp_ro = spacy.blank(\"ro\")\n",
    "pos_debug = True\n",
    "addEvaluation = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91204b68-6aac-48da-8b88-bbfc0f7e65af",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for ix,current_doc in enumerate(spacyDocuments.get_docs(blank_nlp_ro.vocab)):\n",
    "    doc_length = len(current_doc)\n",
    "    f_ix = f'{ix+1:03}'\n",
    "    print(\"<\" + str(f_ix) + \">\" + \" . . . . . . . . . . . . . . . . . . .\")\n",
    "    print(\"<\" + str(f_ix) + \">\" + \" . . . . . . . . . . . . . . . . . . .\", file=open(logFile, 'a'))\n",
    "    print(\"[\" + str(doc_length) + \" items] \" + str(current_doc))\n",
    "    print(\"[\" + str(doc_length) + \" items] \" + str(current_doc), file=open(logFile, 'a'))\n",
    "    print(\"........................\", file=open(logFile, 'a'))\n",
    "    output_tokens = []\n",
    "    in_tokens = []\n",
    "    output_variants = []\n",
    "    \n",
    "    for token in current_doc:\n",
    "        if pos_debug:\n",
    "            print(str(token.i) + \" \" + token.text + \" \" + token.lower_ + \" \" + \\\n",
    "            token.pos_ + \" \" + token.tag_ + \" \" + token.dep_, file=open(logFile, 'a'))\n",
    "\n",
    "        r_nbor = get_rnbor(token)\n",
    "        l_nbor = get_lnbor(token)\n",
    "        surface_form = \"\"\n",
    "        interim_form = \"\"\n",
    "        postverbal_hyphen = \"\"\n",
    "        surface_forms = []\n",
    "        \n",
    "        # 1. current token is a Linear Order Part (LOP), i.e., can occur both pre- and post-verbally\n",
    "        if token._.is_linear_order_part:\n",
    "            is_postverbal_token = not is_preverbal(token) and not r_nbor.pos_ == 'VERB'\n",
    "            if is_postverbal_token:\n",
    "                postverbal_hyphen = HYPHEN_TOKEN.text\n",
    "\n",
    "            # 1.1 current token is a Romanian Weak Pronoun (RWP) or a Romanian Weak Verb (RWV)\n",
    "            if  token._.is_rwp or token._.is_rwv:\n",
    "                # 1.1.1 RWP rightmost item in the cluster\n",
    "                if is_rightmost_in_cluster(token):\n",
    "                    \n",
    "                    # cope with ni => ne, vi => vă, and li => le\n",
    "                    interim_form = get_interim_form(token.lower_)\n",
    "                    \n",
    "                    # 1.1.1.1 obligatory sandhi to the right\n",
    "                    if r_nbor._.is_obligatory_host:\n",
    "                        surface_form = get_asyllabic_form(interim_form, \"OBLIGATORY\") + HYPHEN_TOKEN.text\n",
    "                        surface_forms.append(postverbal_hyphen+surface_form)\n",
    "\n",
    "                    # 1.1.1.2 no obligatory host to the right\n",
    "                    else:\n",
    "                        \n",
    "                        # 1.1.1.2.1 obligatory sandhi to the left for the u- and i-forms (lu ==> -l, mi ==> -mi)\n",
    "                        if l_nbor._.is_rwp:\n",
    "                            # 1.1.1.2.1.1 e- or ă-forms\n",
    "                            if ('e' in interim_form) or ('ă' in interim_form):\n",
    "                                surface_form = interim_form\n",
    "                                surface_forms.append(postverbal_hyphen+surface_form)\n",
    "                                ## check for optional sandhi\n",
    "                                if r_nbor._.vowel_initial_char and r_nbor._.vowel_initial and not \\\n",
    "                                   r_nbor._.is_first_syllable_stressed and not r_nbor.lower_.startswith('o') and not\\\n",
    "                                   r_nbor.lower_.startswith('e'):\n",
    "                                    surface_form = get_asyllabic_form(interim_form, \"OPTIONAL\") + HYPHEN_TOKEN.text\n",
    "                                    surface_forms.append(postverbal_hyphen+surface_form)\n",
    "\n",
    "                                \n",
    "                            # 1.1.1.2.1.2 i- or u-forms\n",
    "                            else:\n",
    "                                surface_form = HYPHEN_TOKEN.text + get_asyllabic_form(interim_form, \"OBLIGATORY\")\n",
    "                                surface_forms.append(postverbal_hyphen+surface_form)\n",
    "                        \n",
    "                        # rightmost AND leftmost item ==> single RWP/RWV\n",
    "                        # check context for different syllabic hosts: to the right, to the left or î-prothetic vowel\n",
    "                        # 1.1.1.2.2 no obligatory sandhi to the left\n",
    "                        else:\n",
    "                            # 1.1.1.2.2.1 e- or ă-forms\n",
    "                            if ('e' in interim_form) or  ('ă' in interim_form):\n",
    "                                surface_form = interim_form\n",
    "                                surface_forms.append(postverbal_hyphen+surface_form)\n",
    "                                ## check for optional sandhi\n",
    "                                if r_nbor._.vowel_initial_char and r_nbor._.vowel_initial and not \\\n",
    "                                   r_nbor._.is_first_syllable_stressed and not r_nbor.lower_.startswith('o') and not\\\n",
    "                                   r_nbor.lower_.startswith('e'):\n",
    "                                    surface_form = get_asyllabic_form(interim_form, \"OPTIONAL\") + HYPHEN_TOKEN.text\n",
    "                                    surface_forms.append(postverbal_hyphen+surface_form)\n",
    "                                # ni-e, vi-e, li-e sete    \n",
    "                                if token.lower_.endswith('i') and ('-pd-' in token.tag_) and \\\n",
    "                                   r_nbor.lower_ == 'e' and r_nbor.pos_ == 'AUX':\n",
    "                                    surface_form = token.text + HYPHEN_TOKEN.text\n",
    "                                    surface_forms.append(postverbal_hyphen+surface_form)\n",
    "                            # 1.1.1.2.2.2 i- or u-forms\n",
    "                            else:\n",
    "                                ## check pre- or post-verbal position\n",
    "                                if is_postverbal_token:\n",
    "                                    surface_form = get_asyllabic_form(interim_form, \"OBLIGATORY\")\n",
    "                                    surface_forms.append(postverbal_hyphen+surface_form)\n",
    "                                else:\n",
    "                                    surface_form = \"î\" + get_asyllabic_form(interim_form, \"OBLIGATORY\")\n",
    "                                    surface_forms.append(postverbal_hyphen+surface_form)\n",
    "                                    # TODO: refine this\n",
    "                                    if r_nbor._.vowel_initial_char and r_nbor._.vowel_initial and not \\\n",
    "                                       r_nbor.lower_.startswith('î') and not r_nbor._.is_first_syllable_stressed:\n",
    "                                        surface_form = get_asyllabic_form(interim_form, \"OBLIGATORY\") + HYPHEN_TOKEN.text\n",
    "                                        surface_forms.append(surface_form)\n",
    "                                        print(\"gogo \" + str(r_nbor._.is_first_syllable_stressed), file=open(logFile, 'a'))\n",
    "                                    # disabiguate VERB.inf RWP VERB.pres: do not attach a RWP to an infinitive (\"*a vedea-i cade greu\") \n",
    "                                    if l_nbor._.vowel_final and not (l_nbor.pos_ == 'VERB' and l_nbor.tag_.startswith('Vmii') and \\\n",
    "                                                                    r_nbor.pos_ == 'VERB' and r_nbor.tag_.startswith('Vmip')):\n",
    "                                        surface_form = HYPHEN_TOKEN.text + get_asyllabic_form(interim_form, \"OBLIGATORY\")\n",
    "                                        surface_forms.append(surface_form)\n",
    "                                    if r_nbor.pos_ == 'VERB' and r_nbor.lower_.startswith('î'):\n",
    "                                        surface_form = token.text + HYPHEN_TOKEN.text\n",
    "                                        surface_forms.append(surface_form)\n",
    "                                    if r_nbor.pos_ == 'VERB' and r_nbor.lower_.startswith('î') and token.lower_ == 'lu':\n",
    "                                        surface_form = get_asyllabic_form(interim_form, \"OBLIGATORY\") + HYPHEN_TOKEN.text\n",
    "                                        surface_forms.append(surface_form)\n",
    "\n",
    "                # 1.1.1 RWP not rightmost item in the cluster\n",
    "                else:\n",
    "                    surface_form = token.text\n",
    "                    surface_forms.append(postverbal_hyphen+surface_form)\n",
    "\n",
    "            # 1.2 current token is not (RWP or RWV), but a LOP, i.e., an auxiliary verb or the o-RWP\n",
    "            else:\n",
    "                surface_form = token.text\n",
    "                surface_forms.append(postverbal_hyphen+surface_form)\n",
    "\n",
    "            output_tokens.append(surface_forms)\n",
    "\n",
    "        # 2. current token is not a LOP\n",
    "        else:\n",
    "            # adjust gerund forms\n",
    "            # ex: dând l afară ==> dându-l afară\n",
    "            if token.pos_ == 'VERB' and token.tag_ == 'Vmg' and r_nbor._.is_rwp:\n",
    "                surface_form = token.text + 'u'\n",
    "                surface_forms.append(surface_form)\n",
    "            # adjust the imperative forms\n",
    "            # ex: uită o/împușcă o ==> uit-o/împușc-o\n",
    "            elif token.pos_ == 'VERB' and token.lower_.endswith('ă') and len(token.lower_) > 2 and r_nbor._.is_vocalic_rwp:\n",
    "                surface_form = token.lower_[:-1]\n",
    "                surface_forms.append(surface_form)\n",
    "            # leave the token as it it    \n",
    "            # ex: Îți dau mere. ==> Îți dau mere.\n",
    "            else: \n",
    "                surface_forms.append(token.text)\n",
    "\n",
    "            # optional sandhi of negation\n",
    "            # ex: nu am văzut ==> n-am văzut\n",
    "            if token.lower_ == 'nu' and r_nbor._.vowel_initial_char and r_nbor._.vowel_initial and not r_nbor.lower_.startswith('î'):\n",
    "                surface_form = token.lower_.replace('u','') + '-'\n",
    "                surface_forms.append(surface_form)\n",
    "\n",
    "            # optional sandhi with of î-forms 'în'/'încolo'\n",
    "            # ex: și încolo ==> și-ncolo\n",
    "            if token.lower_.startswith('î') and l_nbor._.vowel_final_char and l_nbor._.vowel_final and l_nbor.lower_ != 'lu' :\n",
    "                surface_form = token.text.replace('î','-',1)\n",
    "                surface_forms.append(surface_form)\n",
    "\n",
    "            # optional sandhi with ă-forms 'să'/'că' \n",
    "            # ex: vreau să o cumperi ==> vreau s-o cumperi\n",
    "            if token.lower_.endswith('ă') and token.pos_ != 'VERB' and r_nbor._.is_vocalic_rwp:\n",
    "                surface_form = token.text.replace('ă','-',1)\n",
    "                surface_forms.append(surface_form)\n",
    "\n",
    "            output_tokens.append(surface_forms)\n",
    "\n",
    "    output_variants = []\n",
    "    print(output_tokens)\n",
    "\n",
    "    for l in itertools.product(*output_tokens):\n",
    "        print(l)\n",
    "        xput = f'{\" \".join(l).replace(\"- \", \"-\").replace(\" -\", \"-\").replace(\"--\", \"-\")}'\n",
    "        xput = f'{xput.replace(\" ,\", \",\").replace(\" ?\", \"?\").replace(\" .\",\".\").replace(\" !\", \"!\")}'\n",
    "        xput = xput[:1].upper() + xput[1:]\n",
    "        xput = re.compile(r\"\\s+\").sub(\" \", xput).strip()\n",
    "        output_variants.append(xput)\n",
    "    \n",
    "    filteredOutput = filterOutput(output_variants)\n",
    "    \n",
    "    print(\"........................\", file=open(logFile, 'a'))\n",
    "    print(filteredOutput, file=open(logFile, 'a'))\n",
    "    print(\"................................................................\")\n",
    "\n",
    "    targets = rwpDB['rwp_db']['ex'+f_ix]['targets']\n",
    "\n",
    "    # insert generation output into the rwpDB\n",
    "    rwpDB['rwp_db']['ex'+f_ix]['output'] = indexOutput(filteredOutput, f_ix, targets)\n",
    "\n",
    "    # insert generation evaluation into the rwpDB\n",
    "    if addEvaluation:\n",
    "        (genEval, progress) = getEvaluation(filteredOutput, f_ix, targets)\n",
    "        rwpDB['rwp_db']['ex'+f_ix]['evaluation'] = genEval\n",
    "        rwpDB['rwp_db']['ex'+f_ix]['ex'+f_ix+'_progress'] = progress\n",
    "\n",
    "    # in loop: ___for current_doc___\n",
    "    print(\"-------------------------------------------\", file=open(logFile, 'a'))\n",
    "\n",
    "print(\"===========================================\", file=open(logFile, 'a'))\n",
    "   \n",
    "with open(genFile, 'w', encoding='utf-8') as f:\n",
    "    json.dump(rwpDB, f, ensure_ascii=False, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb79a08c-5c74-4b16-b8c7-403a8fcd43bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rwp_gen-kernel",
   "language": "python",
   "name": "rwp_gen-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
